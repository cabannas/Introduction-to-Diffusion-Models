{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim: int):\n",
    "    \"\"\"\n",
    "    Retrieved from https://github.com/hojonathanho/diffusion/blob/master/diffusion_tf/nn.py#LL90C1-L109C13\n",
    "    Retrieved from https://www.udemy.com/course/diffusion-models/learn/lecture/37971218#overview\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(timesteps.shape) == 1\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = timesteps.type(torch.float32) [:, None] *emb[None, :]\n",
    "    emb = torch.concat([torch.sin(emb), torch.cos(emb)], axis=1)\n",
    "\n",
    "    if embedding_dim % 2 == 1: # zero pad\n",
    "        emb = torch.pad(emb, [[0, 0], [0, 1]])\n",
    "    \n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim), f\"{emb.shape}\"\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsample(nn.Module):\n",
    "  \n",
    "    def __init__(self,C):\n",
    "        \"\"\"\n",
    "        :param C (int): number of input and output channels\n",
    "        \"\"\"\n",
    "        super(Downsample, self).__init__()\n",
    "        self.conv = nn.Conv2d(C, C, 3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.conv(x)\n",
    "        assert x.shape == (B, C, H // 2, W // 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "  \n",
    "    def __init__(self,C):\n",
    "        \"\"\"\n",
    "        :param C (int): number of input and output channels\n",
    "        \"\"\"\n",
    "        super(Upsample, self).__init__()\n",
    "        self.conv = nn.Conv2d(C, C, 3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        x = nn.functional.interpolate(x, size=None, scale_factor=2, mode='nearest')\n",
    "\n",
    "        x = self.conv(x)\n",
    "        assert x.shape == (B, C, H * 2, W * 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nin(nn.Module):\n",
    "  \n",
    "    def __init__(self, in_dim, out_dim, scale = 1e-10):\n",
    "        super(Nin, self).__init__()\n",
    "\n",
    "        n = (in_dim + out_dim) / 2\n",
    "        limit = np.sqrt(3 * scale / n)\n",
    "        self.W = torch.nn.Parameter(torch.zeros((in_dim, out_dim), dtype=torch.float32).uniform_(-limit, limit))\n",
    "        self.b = torch.nn.Parameter(torch.zeros((1, out_dim, 1, 1), dtype=torch.float32))\n",
    "\n",
    "    def forward(self,x ):\n",
    "        return torch.einsum('bchw, co->bowh', x, self.W) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, dropout_rate=0.1):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1)\n",
    "        self.dense = nn.Linear(512, out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1)\n",
    "\n",
    "        if in_ch != out_ch:\n",
    "            self.nin = Nin(in_ch, out_ch)\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.nonlinearity = torch.nn.SiLU()\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        \"\"\"\n",
    "        :param x: (B, C, H, W)\n",
    "        :param temb: (B, dim)\n",
    "        \"\"\"\n",
    "\n",
    "        h = self.nonlinearity(nn.functional.group_norm(x, num_groups=32))\n",
    "        h = self.conv1(x)\n",
    "\n",
    "        # add in timestep embedding\n",
    "        h += self.dense(self.nonlinearity(temb))[:, :, None, None]\n",
    "\n",
    "        h = self.nonlinearity(nn.functional.group_norm(h, num_groups=32))\n",
    "        h = nn.functional.dropout(h, p=self.dropout_rate)\n",
    "        h = self.conv2(h)\n",
    "\n",
    "        if x.shape[1] != h.shape[1]:\n",
    "            x = self.nin(x)\n",
    "\n",
    "        assert x.shape == h.shape\n",
    "        return x + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, ch):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "\n",
    "        self.Q = Nin(ch, ch)\n",
    "        self.K = Nin(ch, ch)\n",
    "        self.V = Nin(ch, ch)\n",
    "\n",
    "        self.ch = ch\n",
    "\n",
    "        self.nin = Nin(ch, ch, scale=0.)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B, C, H, W = x.shape\n",
    "        assert C == self.ch\n",
    "\n",
    "        h = nn. functional.group_norm(x, num_groups=32)\n",
    "        q = self.Q(h)\n",
    "        k = self.K(h)\n",
    "        v = self.V(h)\n",
    "\n",
    "        w = torch.einsum('bchw,bcHW->bhwHW', q, k) * (int(C) ** (-0.5)) # [B, H, W, H, W]\n",
    "        w = torch.reshape(w, [B, H, W, H * W])\n",
    "        w = torch.nn.functional.softmax(w, dim=-1)\n",
    "        w = torch.reshape(w, [B, H, W, H, W])\n",
    "\n",
    "        h = torch.einsum('bhwHW,bcHW->bchw', w, v)\n",
    "        h = self.nin(h)\n",
    "\n",
    "        assert h.shape == x.shape\n",
    "        return x + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, ch=128, in_ch=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.ch = ch\n",
    "        self.linear1 = nn.Linear(ch, 4 * ch)\n",
    "        self.linear2 = nn.Linear(4 * ch, 4 * ch)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_ch, ch, 3, stride=1, padding=1)\n",
    "\n",
    "        # Downsampling\n",
    "        self.down = nn.ModuleList([ResNetBlock(ch, 1 * ch), # 32 x 32\n",
    "                                   ResNetBlock(1 * ch, 1 * ch),\n",
    "                                   Downsample(1 * ch), # 16 x 16\n",
    "\n",
    "                                   ResNetBlock(1 * ch, 2 * ch),\n",
    "                                   AttentionBlock(2 * ch),\n",
    "\n",
    "                                   ResNetBlock(2 * ch, 2 * ch),\n",
    "                                   AttentionBlock(2 * ch),\n",
    "                                   Downsample(2 * ch),\n",
    "\n",
    "                                   ResNetBlock(2 * ch, 2 * ch), \n",
    "                                   ResNetBlock(2 * ch, 2 * ch),\n",
    "                                   Downsample(2 * ch),\n",
    "\n",
    "                                   ResNetBlock(2 * ch, 2 * ch), \n",
    "                                   ResNetBlock(2 * ch, 2 * ch)])\n",
    "        \n",
    "        # Middle\n",
    "        self.middle = nn.ModuleList([ResNetBlock(2 * ch, 2 * ch),\n",
    "                                     AttentionBlock(2 * ch),\n",
    "                                     ResNetBlock(2 * ch, 2 * ch)])\n",
    "        \n",
    "        # Upscaling\n",
    "        self.up = nn.ModuleList([ResNetBlock(4 * ch, 2 * ch), # 4 x 4\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 Upsample(2 * ch), \n",
    "\n",
    "                                 ResNetBlock(4 * ch, 2 * ch), # 8 x 8\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 Upsample(2 * ch), # 16 x 16\n",
    "\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 AttentionBlock(2 * ch),\n",
    "\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 AttentionBlock(2 * ch),\n",
    "\n",
    "                                 ResNetBlock(3 * ch, 2 * ch), # 3 channel \n",
    "                                 AttentionBlock(2 * ch),\n",
    "                                 Upsample(2 * ch),\n",
    "\n",
    "                                 ResNetBlock(3 * ch, 1 * ch),\n",
    "                                 ResNetBlock(2 * ch, 1 * ch),\n",
    "                                 ResNetBlock(2 * ch, 1 * ch)]) \n",
    "        \n",
    "\n",
    "        self.final_conv = nn.Conv2d(ch, in_ch, 3, stride=1, padding=1)\n",
    "                                   \n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\" \n",
    "        :param x (torch.Tensor): batch of images [B, C, H, W]\n",
    "        :param t (torch.Tensor): tensor of time steps (torch.long) [B]\n",
    "        \"\"\"\n",
    "\n",
    "        # Timestep embedding\n",
    "        temb = get_timestep_embedding(t, self.ch)\n",
    "        temb = torch.nn.functional.silu(self.linear1(temb))\n",
    "        temb = self.linear2(temb)\n",
    "        assert temb.shape == (t.shape[0], self.ch *4)\n",
    "\n",
    "        # Downsampling\n",
    "        x1 = self.conv1(x)\n",
    "\n",
    "        x2 = self.down[0](x1, temb)\n",
    "        x3 = self.down[1](x2, temb)\n",
    "        x4 = self.down[2](x3)\n",
    "        x5 = self.down[3](x4, temb)\n",
    "        x6 = self.down[4](x5)   # Attention\n",
    "        x7 = self.down[5](x6, temb)\n",
    "        x8 = self.down[6](x7)   # Attention\n",
    "        x9 = self.down[7](x8)\n",
    "        x10 = self.down[8](x9, temb)\n",
    "        x11 = self.down[9](x10, temb)\n",
    "        x12 = self.down[10](x11)\n",
    "        x13 = self.down[11](x12, temb)\n",
    "        x14 = self.down[12](x13, temb)\n",
    "\n",
    "        # Middle\n",
    "        x = self.middle[0](x14, temb)\n",
    "        x = self.middle[1](x)\n",
    "        x = self.middle[2](x, temb)\n",
    "\n",
    "        # Upsampling\n",
    "        x = self.up[0](torch.cat((x, x14), dim=1), temb)\n",
    "        x = self.up[1](torch.cat((x, x13), dim=1), temb)\n",
    "        x = self.up[2](torch.cat((x, x12), dim=1), temb)\n",
    "        x = self.up[3](x)\n",
    "        x = self.up[4](torch.cat((x, x11), dim=1), temb)\n",
    "        x = self.up[5](torch.cat((x, x10), dim=1), temb)\n",
    "        x = self.up[6](torch.cat((x, x9), dim=1), temb)\n",
    "        x = self.up[7](x)\n",
    "        x = self.up[8](torch.cat((x, x8), dim=1), temb)\n",
    "        x = self.up[9](x)\n",
    "        x = self.up[10](torch.cat((x, x6), dim=1), temb)\n",
    "        x = self.up[11](x)\n",
    "        x = self.up[12](torch.cat((x, x4), dim=1), temb)\n",
    "        x = self.up[13](x)\n",
    "        x = self.up[14](x)\n",
    "        x = self.up[15](torch.cat((x, x3), dim=1), temb)\n",
    "        x = self.up[16](torch.cat((x, x2), dim=1), temb)\n",
    "        x = self.up[17](torch.cat((x, x1), dim=1), temb)\n",
    "\n",
    "\n",
    "        x = nn.functional.silu(nn.functional.group_norm(x, num_groups=32))\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (torch.rand(10) * 10).long()\n",
    "temb = get_timestep_embedding(t, 512)\n",
    "\n",
    "downsample = Downsample(64)\n",
    "img = torch.randn((10, 64, 16, 16))\n",
    "img = downsample(img)\n",
    "\n",
    "upsample = Upsample(64)\n",
    "img = upsample(img)\n",
    "\n",
    "nin = Nin(64, 128)\n",
    "img = nin(img)\n",
    "\n",
    "resnet = ResNetBlock(128, 128, 0.1)\n",
    "img = resnet(img, temb)\n",
    "\n",
    "resnet = ResNetBlock(128, 64, 0.1)\n",
    "img = resnet(img, temb)\n",
    "\n",
    "att = AttentionBlock(64)\n",
    "img = att(img)\n",
    "\n",
    "img = torch.randn((10, 1, 32, 32))\n",
    "model = UNet()\n",
    "img = model(img, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.713281"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()]) / 1e6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
