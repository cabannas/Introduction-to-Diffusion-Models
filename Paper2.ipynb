{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim: int):\n",
    "    \"\"\"\n",
    "    Retrieved from https://github.com/hojonathanho/diffusion/blob/master/diffusion_tf/nn.py#LL90C1-L109C13\n",
    "    Retrieved from https://www.udemy.com/course/diffusion-models/learn/lecture/37971218#overview\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(timesteps.shape) == 1\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = timesteps.type(torch.float32) [:, None] *emb[None, :]\n",
    "    emb = torch.concat([torch.sin(emb), torch.cos(emb)], axis=1)\n",
    "\n",
    "    if embedding_dim % 2 == 1: # zero pad\n",
    "        emb = torch.pad(emb, [[0, 0], [0, 1]])\n",
    "    \n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim), f\"{emb.shape}\"\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsample(nn.Module):\n",
    "  \n",
    "    def __init__(self,C):\n",
    "        \"\"\"\n",
    "        :param C (int): number of input and output channels\n",
    "        \"\"\"\n",
    "        super(Downsample, self).__init__()\n",
    "        self.conv = nn.Conv2d(C, C, 3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.conv(x)\n",
    "        assert x.shape == (B, C, H // 2, W // 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "  \n",
    "    def __init__(self,C):\n",
    "        \"\"\"\n",
    "        :param C (int): number of input and output channels\n",
    "        \"\"\"\n",
    "        super(Upsample, self).__init__()\n",
    "        self.conv = nn.Conv2d(C, C, 3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        x = nn.functional.interpolate(x, size=None, scale_factor=2, mode='nearest')\n",
    "\n",
    "        x = self.conv(x)\n",
    "        assert x.shape == (B, C, H * 2, W * 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nin(nn.Module):\n",
    "  \n",
    "    def __init__(self, in_dim, out_dim, scale = 1e-10):\n",
    "        super(Nin, self).__init__()\n",
    "\n",
    "        n = (in_dim + out_dim) / 2\n",
    "        limit = np.sqrt(3 * scale / n)\n",
    "        self.W = torch.nn.Parameter(torch.zeros((in_dim, out_dim), dtype=torch.float32).uniform_(-limit, limit))\n",
    "        self.b = torch.nn.Parameter(torch.zeros((1, out_dim, 1, 1), dtype=torch.float32))\n",
    "\n",
    "    def forward(self,x ):\n",
    "        return torch.einsum('bchw, co->bowh', x, self.W) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, dropout_rate):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1)\n",
    "        self.dense = nn.Linear(512, out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1)\n",
    "\n",
    "        if in_ch != out_ch:\n",
    "            self.nin = Nin(in_ch, out_ch)\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.nonlinearity = torch.nn.SiLU()\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        \"\"\"\n",
    "        :param x: (B, C, H, W)\n",
    "        :param temb: (B, dim)\n",
    "        \"\"\"\n",
    "\n",
    "        h = self.nonlinearity(nn.functional.group_norm(x, num_groups=32))\n",
    "        h = self.conv1(x)\n",
    "\n",
    "        # add in timestep embedding\n",
    "        h += self.dense(self.nonlinearity(temb))[:, :, None, None]\n",
    "\n",
    "        h = self.nonlinearity(nn.functional.group_norm(h, num_groups=32))\n",
    "        h = nn.functional.dropout(h, p=self.dropout_rate)\n",
    "        h = self.conv2(h)\n",
    "\n",
    "        if x.shape[1] != h.shape[1]:\n",
    "            x = self.nin(x)\n",
    "\n",
    "        assert x.shape == h.shape\n",
    "        return x + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import scale\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, ch):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "\n",
    "        self.Q = Nin(ch, ch)\n",
    "        self.K = Nin(ch, ch)\n",
    "        self.V = Nin(ch, ch)\n",
    "\n",
    "        self.ch = ch\n",
    "\n",
    "        self.nin = Nin(ch, ch, scale==0.)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        B, C, H, W = x.shape\n",
    "        assert C == self.ch\n",
    "\n",
    "        h = nn. functional.group_norm(x, num_groups=32)\n",
    "        q = self.Q(h)\n",
    "        k = self.K(h)\n",
    "        v = self.V(h)\n",
    "\n",
    "        w = torch.einsum('bchw,bcHW->bhwHW', q, k) * (int(C) ** (-0.5)) # [B, H, W, H, W]\n",
    "        w = torch.reshape(w, [B, H, W, H * W])\n",
    "        w = torch.nn.functional.softmax(w, dim=-1)\n",
    "        w = torch.reshape(w, [B, H, W, H, W])\n",
    "\n",
    "        h = torch.einsum('bhwHW,bcHW->bchw', w, v)\n",
    "        h = self.nin(h)\n",
    "\n",
    "        assert h.shape == x.shape\n",
    "        return x + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (torch.rand(10) * 10).long()\n",
    "temb = get_timestep_embedding(t, 512)\n",
    "\n",
    "downsample = Downsample(64)\n",
    "img = torch.randn((10, 64, 16, 16))\n",
    "img = downsample(img)\n",
    "\n",
    "upsample = Upsample(64)\n",
    "img = upsample(img)\n",
    "\n",
    "nin = Nin(64, 128)\n",
    "img = nin(img)\n",
    "\n",
    "resnet = ResNetBlock(128, 128, 0.1)\n",
    "img = resnet(img, temb)\n",
    "\n",
    "resnet = ResNetBlock(128, 64, 0.1)\n",
    "img = resnet(img, temb)\n",
    "\n",
    "att = AttentionBlock(64)\n",
    "img = att(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64, 16, 16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
